{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38206bae",
   "metadata": {},
   "source": [
    "# DQN CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a621a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethem\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ac92e",
   "metadata": {},
   "source": [
    "### Ortamı Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526a31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1') # CartPole ortamını tanımlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85148542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.shape[0]) # durum 4 değerden oluşan bir vektördür\n",
    "print(env.action_space.n) # yapılabilecek 2 adet eylem var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307adfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.0039746 , -0.20175163,  0.0095587 ,  0.31600395], dtype=float32), 1.0, False, False, {})\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = env.action_space.sample() # eylem uzayından rastgele eylem seçilir\n",
    "result = env.step(action) # eylem gerçekleştirilir ve sonuç alınır\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ead1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0039746  -0.20175163  0.0095587   0.31600395] 1.0 False\n"
     ]
    }
   ],
   "source": [
    "state, reward, done = result[:3] \n",
    "# state, reward, done, _, _ = result \n",
    "print(state, reward, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816dcefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01694924 -0.19549517 -0.02947601  0.27168965] 1.0 False\n",
      "[-0.02085914 -0.39018437 -0.02404222  0.55493194] 1.0 False\n",
      "[-0.02866283 -0.58496064 -0.01294358  0.8399442 ] 1.0 False\n",
      "[-0.04036204 -0.38966438  0.00385531  0.54321903] 1.0 False\n",
      "[-0.04815533 -0.19459684  0.01471969  0.2517533 ] 1.0 False\n",
      "[-0.05204727  0.00031186  0.01975475 -0.03625064] 1.0 False\n",
      "[-0.05204103 -0.19508772  0.01902974  0.26259905] 1.0 False\n",
      "[-0.05594278 -0.0002425   0.02428172 -0.02402144] 1.0 False\n",
      "[-0.05594763  0.19452296  0.02380129 -0.3089454 ] 1.0 False\n",
      "[-0.05205717 -0.00092989  0.01762238 -0.00885224] 1.0 False\n",
      "[-0.05207577  0.19393496  0.01744534 -0.2959234 ] 1.0 False\n",
      "[-0.04819707 -0.00143129  0.01152687  0.00221004] 1.0 False\n",
      "[-0.0482257   0.19352347  0.01157107 -0.28681386] 1.0 False\n",
      "[-0.04435523  0.38847852  0.00583479 -0.57582504] 1.0 False\n",
      "[-0.03658566  0.5835182  -0.00568171 -0.8666641 ] 1.0 False\n",
      "[-0.02491529  0.778717   -0.02301499 -1.161128  ] 1.0 False\n",
      "[-0.00934095  0.97413105 -0.04623755 -1.4609373 ] 1.0 False\n",
      "[ 0.01014167  0.77960545 -0.07545629 -1.1830497 ] 1.0 False\n",
      "[ 0.02573377  0.5855393  -0.09911729 -0.9149419 ] 1.0 False\n",
      "[ 0.03744456  0.78185195 -0.11741613 -1.2370584 ] 1.0 False\n",
      "[ 0.0530816  0.9782703 -0.1421573 -1.5640984] 1.0 False\n",
      "[ 0.07264701  0.7851053  -0.17343926 -1.3189273 ] 1.0 False\n",
      "[ 0.08834911  0.9819432  -0.1998178  -1.6604904 ] 1.0 False\n",
      "[ 0.10798798  0.7896317  -0.23302762 -1.4361191 ] 1.0 True\n"
     ]
    }
   ],
   "source": [
    "#Ajan eğitilmediğinde bu şekilde çalışır\n",
    "env.reset()\n",
    "while True:\n",
    "    #env.render() CartPole ortamı için render çalışmıyor\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done = env.step(action)[:3]\n",
    "    print(state, reward, done)\n",
    "    if done: # bölümün bitimini gerçekleştirme\n",
    "        env.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2be8e",
   "metadata": {},
   "source": [
    "### Ajanı Tanımlama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7e97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametreler\n",
    "ACTION_SIZE = env.action_space.n\n",
    "STATE_SIZE = env.observation_space.shape[0]\n",
    "GAMMA = 0.95           # indirim faktörü\n",
    "BATCH_SIZE = 32        # \n",
    "LR = 0.0001            # öğrenme hızı \n",
    "EPS_START = 1          # epsilon değeri\n",
    "EPS_MIN = 0.01         # epsilon bitiş değeri\n",
    "EPS_DECAY = 0.995      # \n",
    "Episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b890ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim= STATE_SIZE, activation= 'relu'))\n",
    "        model.add(Dense(24, activation= 'relu'))\n",
    "        model.add(Dense(ACTION_SIZE, activation= 'linear'))\n",
    "        model.compile(loss= 'mse', optimizer=Adam(lr= LR))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f4234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
